{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWDKhtNiyN13",
    "outputId": "3a69aaad-5ea0-43d8-fd5a-b0609d64e416"
   },
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFlztlx1-nEj"
   },
   "source": [
    "# Question 1\n",
    "\n",
    "Implement the dp_occupation_histogram function below. It should return a differentially private histogram over the Occupation column in the adult dataset. Your function should have a total privacy cost of epsilon and should use parallel composition.\n",
    "(use laplace mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZySpAGaJyxbg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prof-specialty': 4140.122095634974,\n",
       " 'Craft-repair': 4099.399509080263,\n",
       " 'Exec-managerial': 4064.7498355752455,\n",
       " 'Adm-clerical': 3771.9462480759767,\n",
       " 'Sales': 3650.5159122066657,\n",
       " 'Other-service': 3295.664737648097,\n",
       " 'Machine-op-inspct': 2001.1383590242187,\n",
       " 'Transport-moving': 1597.692791407002,\n",
       " 'Handlers-cleaners': 1370.4671878252873,\n",
       " 'Farming-fishing': 993.7704842362438,\n",
       " 'Tech-support': 928.357711358345,\n",
       " 'Protective-serv': 649.5887650736229,\n",
       " 'Priv-house-serv': 147.02346388150212,\n",
       " 'Armed-Forces': 8.63443057503427,\n",
       " 'Baby': -0.41350212649013907}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_occupation_histogram(epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    # Calculate sensitivity\n",
    "    sensitivity = 1  # Sensitivity of counting queries\n",
    "\n",
    "    # Compute the non-private histogram\n",
    "    non_private_histogram = adult['Occupation'].value_counts().to_dict()\n",
    "\n",
    "    # Add Laplace noise to each count\n",
    "    dp_histogram = {}\n",
    "    for occupation, count in non_private_histogram.items():\n",
    "        noisy_count = laplace_mech(count, sensitivity, epsilon)\n",
    "        dp_histogram[occupation] = noisy_count\n",
    "\n",
    "    return dp_histogram\n",
    "\n",
    "dp_occupation_histogram(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hF8wzWTX_9R8"
   },
   "source": [
    "\\begin{equation}\n",
    "\\text{Let's denote the differentially private histogram of the 'Occupation' column in the adult dataset with a privacy parameter (epsilon) of 1.0 as } H_{\\text{DP}}^{(1)}, \\text{ and the true histogram as } H_{\\text{True}}. \\text{ The absolute difference between the elements of these histograms is denoted as } \\Delta H^{(1)} = | H_{\\text{DP}}^{(1)} - H_{\\text{True}} |. \\\\\n",
    "\\text{Now, considering a set of } N = 200 \\text{ repetitions, we can represent the expression as a sequence:} \\\\\n",
    "\\Delta H^{(1)}_1, \\Delta H^{(1)}_2, \\Delta H^{(1)}_3, \\ldots, \\Delta H^{(1)}_N \\\\\n",
    "\\text{Where each } \\Delta H^{(1)}_i \\text{ represents the absolute differences between the differentially private histogram and the true histogram for the } i^{th} \\text{ repetition.} \\\\\n",
    "\\text{Mathematically, each } \\Delta H^{(1)}_i \\text{ can be calculated using the formula:} \\\\\n",
    "\\Delta H^{(1)}_i = | H_{\\text{DP}}^{(1)} - H_{\\text{True}} | \\\\\n",
    "\\text{Finally, the entire expression can be written as a list comprehension:} \\\\\n",
    "\\text{dp_results} = [ \\Delta H^{(1)}_i \\text{ for } i \\text{ in range}(N) ] \\\\\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oksoek7rA2fT"
   },
   "source": [
    "Based on above answer these questions:\n",
    "\n",
    "1) Generate 200 differentially private histograms with epsilon value=1\n",
    "\n",
    "2)Compute the DP results \"dp_rseults\"\n",
    "\n",
    "3)Flatten the list of histograms into a single list of absolute differences\n",
    "\n",
    "4)Generate a sample of Laplace noise with scale = 1/1.0 and generate a list of 2000 samples\n",
    "\n",
    "5)What is the  Wasserstein distance between the differential private results list above and the Laplace noise, what  is the integer upper bound\n",
    "\n",
    "6)can you  assert that the Wasserstein distance between the differential private results and the Laplace noise is greater than 0,write the code\n",
    "\n",
    "7)If you partition the data by both occupation and age (i.e. a contingency table), would parallel composition still apply? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqKVTDZDFiMg"
   },
   "source": [
    "Your answer to each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "dp_histograms = [dp_occupation_histogram(epsilon) for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_histogram = adult['Occupation'].value_counts().to_dict()\n",
    "dp_results = [{occupation: abs(dp_histogram[occupation] - true_histogram.get(occupation, 0)) for occupation in set(dp_histogram) | set(true_histogram)} for dp_histogram in dp_histograms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_differences = [count for dp_result in dp_results for count in dp_result.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_noise = np.random.laplace(loc=0, scale=1/epsilon, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein distance: 0.9338226079387666\n",
      "Integer upper bound: 1\n"
     ]
    }
   ],
   "source": [
    "wasserstein_distance = stats.wasserstein_distance(absolute_differences, laplace_noise)\n",
    "upper_bound = int(np.ceil(wasserstein_distance))\n",
    "print(\"Wasserstein distance:\", wasserstein_distance)\n",
    "print(\"Integer upper bound:\", upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert wasserstein_distance > 0, \"Wasserstein distance is not greater than 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.7\n",
    "If you partition the data by both occupation and age (i.e., a contingency table), parallel composition would still apply. This is because parallel composition applies to independent computations over disjoint subsets of the data. As long as the privacy guarantees hold for each subset individually, they can be combined using parallel composition. However, if there are dependencies between the subsets (e.g., correlations between occupation and age), parallel composition may not apply directly. In such cases, more sophisticated privacy analysis techniques would be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHeRkib2VqJC"
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-174mgDVlRN",
    "outputId": "43f7413b-c474-4595-ce63-7fa7ae1fbcea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17145231, 14755, 1360238]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Consider the code below, which defines three average queries and runs them on adult_data, using the Laplace mechanism to provide differential privacy with for each query.\n",
    "\n",
    "b_capgain = 10000\n",
    "b_age = 3000\n",
    "\n",
    "epsilon = 1\n",
    "\n",
    "def query1():\n",
    "    return np.sum(adult['Capital Gain'].clip(lower=0, upper=b_capgain))\n",
    "\n",
    "def query2():\n",
    "    return len(adult[adult['Education-Num'] < 10])\n",
    "\n",
    "def query3():\n",
    "    return np.sum(adult['Age'].clip(lower=0, upper=b_age))\n",
    "\n",
    "def my_query():\n",
    "    return [query1(), query2(), query3()]\n",
    "\n",
    "my_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8jEbz4uVzvI"
   },
   "source": [
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "1)What is the L_1\n",
    " global sensitivity of my_query, and why?\n",
    "2)What is the L_2\n",
    " global sensitivity of my_query, and why?\n",
    "\n",
    "3)Can you release my_query with DP using paraellel compossition with epsilon =1( use L_1 sensitivity), write the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The L1 global sensitivity of my_query is the maximum absolute difference between the outputs of my_query on any pair of neighboring datasets, where neighboring datasets differ by at most one individual's data entry. For my_query, the maximum absolute difference in outputs occurs when one individual's data entry changes in either the 'Capital Gain' or 'Age' column. Therefore, the L1 global sensitivity is the maximum absolute change in the sum of 'Capital Gain' or 'Age' due to a single individual's data entry, which can be bounded by b_capgain or b_age, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The L2 global sensitivity of my_query is the square root of the sum of squares of the individual sensitivities of each query function. Since each query function operates on a single column of the dataset, the L2 sensitivity of each query is the same as the L1 sensitivity (i.e., b_capgain for query1 and query3, and 1 for query2). Therefore, the L2 global sensitivity of my_query is the square root of the sum of squares of b_capgain and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Yes, my_query can be released with differential privacy using parallel composition with epsilon = 1 and L1 sensitivity. We can add Laplace noise with scale equal to the L1 sensitivity of my_query. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17134709.47030449, 4233.470304490036, 1349716.47030449]\n"
     ]
    }
   ],
   "source": [
    "sensitivity = max(b_capgain, b_age)  # L1 sensitivity\n",
    "epsilon = 1\n",
    "noisy_result = laplace_mech(np.array(my_query()), sensitivity, epsilon)\n",
    "print(noisy_result.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKi9MowSiqcd"
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('adult_processed_x.npy')\n",
    "y = np.load('adult_processed_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9044,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_grad(theta, X, y):\n",
    "    grads = [gradient(theta, xi, yi) for xi, yi in zip(X, y)]\n",
    "    return np.mean(grads, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVo8fBTL-v2B"
   },
   "source": [
    "# Implement noisy_gradient_descent_RDP, a variant of noisy gradient descent that uses Rényi differential privacy. Your solution should have a total privacy cost of $(\\alpha, \\bar{\\epsilon})$-RDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Cx7Iuk3k3dVM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.6636444051304733\n"
     ]
    }
   ],
   "source": [
    "def gaussian_mech_RDP_vec(vec, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_RDP(iterations, alpha, epsilon_bar):\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    # Initial guess for theta\n",
    "    theta = np.zeros(X_train.shape[1])  # Assuming theta is of the same dimension as the features\n",
    "    \n",
    "    for t in range(iterations):\n",
    "        # Compute noisy average gradient using Gaussian mechanism with RDP\n",
    "        noisy_avg_grad = gaussian_mech_RDP_vec(avg_grad(theta, X_train, y_train), 1, alpha, epsilon_bar / iterations)\n",
    "        \n",
    "        # Update theta\n",
    "        theta = theta - noisy_avg_grad\n",
    "        \n",
    "    return theta\n",
    "\n",
    "theta = noisy_gradient_descent_RDP(10, 20, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))  # use accuracy same as used in the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKZ8tbFxRHf2"
   },
   "source": [
    "# Implement noisy_gradient_descent_zCDP, a variant of noisy gradient descent that uses zero-concentrated differential privacy. Your solution should have a total privacy cost of -zCDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hg5XqrrtRLBA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.7393852277753207\n"
     ]
    }
   ],
   "source": [
    "def gaussian_mech_zCDP_vec(vec, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_zCDP(iterations, rho):\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    # Initial guess for theta\n",
    "    theta = np.zeros(X.shape[1])  # Assuming theta is of the same dimension as the features\n",
    "    \n",
    "    for t in range(iterations):\n",
    "        # Compute noisy average gradient using Gaussian mechanism with zCDP\n",
    "        noisy_avg_grad = gaussian_mech_zCDP_vec(avg_grad(theta, X_train, y_train), 1, rho)\n",
    "        \n",
    "        # Update theta\n",
    "        theta = theta - noisy_avg_grad\n",
    "        \n",
    "    return theta\n",
    "\n",
    "\n",
    "theta = noisy_gradient_descent_zCDP(10, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKBYV5A3Rb4v"
   },
   "source": [
    "Which of the following functions is likely to produce the best accuracy for a given privacy cost, and why? Which is likely to produce the worst accuracy for a given privacy cost, and why?( use the same dataset as used in notebook for noisy gradient descent for all cases)\n",
    "\n",
    "\n",
    "- noisy_gradient_descent\n",
    "- noisy_gradient_descent_RDP\n",
    "- noisy_gradient_descent_zCDP\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess which function is likely to produce the best accuracy for a given privacy cost, and which is likely to produce the worst accuracy, let's consider the privacy properties of each mechanism:\n",
    "\n",
    "**1. noisy_gradient_descent:**\n",
    "\n",
    "- This mechanism adds Gaussian noise directly to the gradients without explicitly considering differential privacy. Therefore, it provides no formal privacy guarantee.\n",
    "As a result, it may offer the best accuracy in terms of utility since it doesn't introduce any additional noise beyond what is necessary for optimization. However, it lacks any privacy guarantee.\n",
    "\n",
    "**2. noisy_gradient_descent_RDP:**\n",
    "\n",
    "- This mechanism uses the Gaussian mechanism with Rényi Differential Privacy (RDP), providing a formal privacy guarantee.\n",
    "By using RDP, it ensures that the privacy cost is quantifiable and controllable, offering a balance between privacy and utility. However, the additional noise introduced for privacy may degrade accuracy compared to noisy_gradient_descent.\n",
    "\n",
    "**3. noisy_gradient_descent_zCDP:**\n",
    "\n",
    "- This mechanism uses the Gaussian mechanism with Zero-Concentrated Differential Privacy (zCDP), which is a relaxed notion of differential privacy.\n",
    "zCDP provides a less stringent privacy guarantee compared to RDP, which may result in less noise being added for a given privacy cost.\n",
    "However, zCDP does not provide as strong privacy guarantees as RDP, which may lead to a trade-off between privacy and utility. In some cases, this mechanism may offer better accuracy than RDP for a given privacy cost, but it may also be less robust in terms of privacy protection.\n",
    "\n",
    "\n",
    "Considering these points, the function likely to produce the best accuracy for a given privacy cost is noisy_gradient_descent, as it does not introduce additional noise beyond what is necessary for optimization. However, it offers no formal privacy guarantee.\n",
    "\n",
    "On the other hand, the function likely to produce the worst accuracy for a given privacy cost is noisy_gradient_descent_RDP. While it provides a formal privacy guarantee through RDP, the additional noise introduced for privacy may degrade accuracy compared to noisy_gradient_descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA_C0JucoeBo"
   },
   "source": [
    " # References\n",
    "\n",
    " https://programming-dp.com/book.pdf\n",
    "\n",
    " https://colab.research.google.com/drive/1wODT0dOa4Jd7b5X4L9aN8Es1MfzvuWAR#scrollTo=TqaQvOMQRx4U\n",
    " ( class notebook part2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
