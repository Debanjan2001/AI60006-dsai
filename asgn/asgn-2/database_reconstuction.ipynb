{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57883bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f8a4b-2ad0-42ca-9a78-e3f41b970f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69a580",
   "metadata": {},
   "source": [
    "# Task-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification.scikitlearn import ScikitlearnLogisticRegression\n",
    "from art.attacks.inference.reconstruction import DatabaseReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb521b-e714-4dcc-8f5f-95bbcaf4d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=512)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94137b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2660ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_private_art = ScikitlearnLogisticRegression(model)\n",
    "dbrecon = DatabaseReconstruction(non_private_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2dcba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_rmse(X_train, x_pred, target_row):\n",
    "    # print(\"Inference RMSE: {}\".format(\n",
    "    # np.sqrt(((X_train[target_row] - x) ** 2).sum() / X_train.shape[1])))\n",
    "    val = np.sqrt(((X_train[target_row] - x_pred) ** 2).sum() / X_train.shape[1])\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7333198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def launch_attack(X_train, y_train, dbrecon):\n",
    "    recon_attempts = []\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for target_row in tqdm(range(len(X_train))):\n",
    "        X_train_removed = np.delete(X_train, target_row, axis=0)\n",
    "        y_train_removed = np.delete(y_train, target_row, axis=0)\n",
    "\n",
    "        x, y = dbrecon.reconstruct(X_train_removed, y_train_removed)\n",
    "        success = (np.argmax(y) == y_train[target_row])\n",
    "        rmse = get_inference_rmse(X_train, x, target_row)\n",
    "\n",
    "        recon_attempts.append(success)\n",
    "        rmse_scores.append(rmse)\n",
    "        \n",
    "    return recon_attempts, rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a756a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_attack(recon_attempts, rmse_scores):\n",
    "    # Calculate the sum of successful recon_attempts\n",
    "    successful_attempts = sum(recon_attempts)\n",
    "    \n",
    "    # Calculate the average of rmse_scores\n",
    "    average_rmse = sum(rmse_scores) / len(rmse_scores) if rmse_scores else 0\n",
    "    \n",
    "    # Print the results nicely\n",
    "    print(f\"Total Successful Reconstructions: {successful_attempts}/{len(recon_attempts)}\")\n",
    "    print(f\"Average RMSE Score: {average_rmse:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_attempts, rmse_scores = launch_attack(X_train, y_train, dbrecon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f495315",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_attack(recon_attempts, rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29ff56",
   "metadata": {},
   "source": [
    "# Task-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Breast Cancer Wisconsin (Diagnostic) dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10240)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_private_art = ScikitlearnLogisticRegression(model)\n",
    "dbrecon = DatabaseReconstruction(non_private_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_attempts, rmse_scores = launch_attack(X_train, y_train, dbrecon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_attack(recon_attempts, rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aab500",
   "metadata": {},
   "source": [
    "Reasons for Failure:\n",
    "If the reconstruction fails, it could be due to various reasons:\n",
    "\n",
    "Overlap between classes: If the classes are not well-separated in the feature space, removing a sample and trying to reconstruct it may result in misclassification, as the decision boundary might not be clear-cut.\n",
    "\n",
    "Highly correlated features: If the features are highly correlated, removing one sample might not significantly affect the decision boundary, leading to successful reconstruction. However, if features are not highly correlated, removing a sample might have a larger impact on the decision boundary, making reconstruction more difficult.\n",
    "\n",
    "Non-linear decision boundary: Logistic regression assumes a linear decision boundary. If the true decision boundary is non-linear, removing samples and attempting reconstruction may fail, as logistic regression cannot capture complex relationships between features.\n",
    "\n",
    "Imbalanced classes: If the classes are imbalanced, removing samples from the majority class might have less impact on the decision boundary compared to removing samples from the minority class.\n",
    "\n",
    "Noise in the data: If the dataset contains noise or outliers, removing samples may not significantly affect the decision boundary, leading to successful reconstruction even if the removed sample is important for classification.\n",
    "\n",
    "It's important to consider these factors when interpreting the results of the reconstruction attack and assessing the security of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier manipulation and visualization\n",
    "df = pd.DataFrame(data=X, columns=data.feature_names)\n",
    "df['target'] = y  # Adding the target variable to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f37ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91888fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d646714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Countplot for the target variable\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db0537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histograms for features to understand distributions\n",
    "df.drop('target', axis=1).hist(bins=20, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777671b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Box plots to check for outliers\n",
    "plt.figure(figsize=(20, 10))\n",
    "df.drop('target', axis=1).boxplot()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640ce5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix to understand relationships between variables\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23454fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pairplot for a subset of features\n",
    "sns.pairplot(df, vars=df.columns[:5], hue='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5b201",
   "metadata": {},
   "source": [
    "# Task-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60632515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnLogisticRegression, ScikitlearnGaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5081d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset for a four-class classification problem\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, n_classes=4, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifiers\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gaussian_nb_model = GaussianNB()\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the Gaussian Naive Bayes model\n",
    "gaussian_nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the training accuracy of both models\n",
    "logistic_accuracy = logistic_model.score(X_train, y_train)\n",
    "gaussian_nb_accuracy = gaussian_nb_model.score(X_train, y_train)\n",
    "\n",
    "print(f\"Logistic Regression Training Accuracy: {logistic_accuracy*100:.2f}%\")\n",
    "print(f\"Gaussian Naive Bayes Training Accuracy: {gaussian_nb_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_private_art1 = ScikitlearnLogisticRegression(logistic_model)\n",
    "dbrecon1 = DatabaseReconstruction(non_private_art1)\n",
    "\n",
    "non_private_art2 = ScikitlearnGaussianNB(gaussian_nb_model)\n",
    "dbrecon2 = DatabaseReconstruction(non_private_art2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaec560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_attack(X_train, y_train, dbrecon1, dbrecon2, target_rows):\n",
    "    lr_recon_attempts = []\n",
    "    lr_rmse_scores = []\n",
    "    nb_recon_attempts = []\n",
    "    nb_rmse_scores = []\n",
    "    \n",
    "    for target_row in tqdm(target_rows):\n",
    "        X_train_removed = np.delete(X_train, target_row, axis=0)\n",
    "        y_train_removed = np.delete(y_train, target_row, axis=0)\n",
    "\n",
    "        x1, y1 = dbrecon1.reconstruct(X_train_removed, y_train_removed)\n",
    "        x2, y2 = dbrecon2.reconstruct(X_train_removed, y_train_removed)\n",
    "        \n",
    "        lr_success = (np.argmax(y1) == y_train[target_row])\n",
    "        lr_rmse = get_inference_rmse(X_train, x1, target_row)\n",
    "        nb_success = (np.argmax(y2) == y_train[target_row])\n",
    "        nb_rmse = get_inference_rmse(X_train, x2, target_row)\n",
    "\n",
    "        lr_recon_attempts.append(lr_success)\n",
    "        lr_rmse_scores.append(lr_rmse)\n",
    "        nb_recon_attempts.append(nb_success)\n",
    "        nb_rmse_scores.append(nb_rmse)\n",
    "        \n",
    "    return lr_recon_attempts, lr_rmse_scores, nb_recon_attempts, nb_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 100 random samples from the dataset\n",
    "np.random.seed(42)\n",
    "target_rows = np.random.choice(range(len(X)), size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_recon_attempts, lr_rmse_scores, nb_recon_attempts, nb_rmse_scores = launch_attack(X_train, y_train, dbrecon1, dbrecon2, target_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_attack(lr_recon_attempts, lr_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_attack(nb_recon_attempts, nb_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95585c",
   "metadata": {},
   "source": [
    "# Task-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffprivlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0912e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import GaussianNB as DPGaussianNB\n",
    "\n",
    "# Initialize the differentially private GaussianNB model\n",
    "# Note: `epsilon` controls the privacy guarantee. A smaller epsilon means more privacy but potentially less accuracy.\n",
    "# `data_norm` is not a parameter for DPGaussianNB, as it works differently from DPLogisticRegression.\n",
    "dp_gaussian_nb_model = DPGaussianNB(epsilon=1.0)\n",
    "\n",
    "# Train the model with differential privacy\n",
    "dp_gaussian_nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate its accuracy on the test set\n",
    "dp_gaussian_nb_accuracy = dp_gaussian_nb_model.score(X_test, y_test)\n",
    "print(f\"Differentially Private GaussianNB Test Accuracy: {dp_gaussian_nb_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c035b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diffprivlib.models import GaussianNB as DPGaussianNB\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "epsilons = np.logspace(-2, 2, 50)\n",
    "accuracies_gnb = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    dp_gnb_model = DPGaussianNB(epsilon=eps)\n",
    "    dp_gnb_model.fit(X_train, y_train)\n",
    "    accuracy = dp_gnb_model.score(X_test, y_test)\n",
    "    accuracies_gnb.append(accuracy)\n",
    "\n",
    "# Plot the accuracy vs epsilon for GaussianNB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(epsilons, accuracies_gnb, label='DP GaussianNB', color='orange')\n",
    "plt.title('Differentially Private GaussianNB: Accuracy vs. Epsilon')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa46cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import LogisticRegression as DPLogisticRegression\n",
    "from diffprivlib.models import GaussianNB as DPGaussianNB\n",
    "\n",
    "# Initialize the differentially private logistic regression model\n",
    "dp_logistic_model = DPLogisticRegression(epsilon=1.0, data_norm=12.0)\n",
    "\n",
    "# Train the model with differential privacy\n",
    "dp_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate its accuracy on the test set\n",
    "dp_logistic_accuracy = dp_logistic_model.score(X_test, y_test)\n",
    "print(f\"Differentially Private Logistic Regression Test Accuracy: {dp_logistic_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c350f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epsilons = np.logspace(-2, 2, 50)\n",
    "accuracies = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    dp_model = DPLogisticRegression(epsilon=eps, data_norm=12.0)\n",
    "    dp_model.fit(X_train, y_train)\n",
    "    accuracy = dp_model.score(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plot the accuracy vs epsilon\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(epsilons, accuracies)\n",
    "plt.title('Accuracy vs. Epsilon')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23910b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
